{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUsQ_odNUd1l"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image, ImageFile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Handle truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Paths for datasets\n",
    "train_dataset_path = r\"biodnonbiodddatset/train\"\n",
    "test_dataset_path = r\"biodnonbiodddatset/val\"\n",
    "\n",
    "# Waste categories (must match dataset folder names)\n",
    "waste_categories = ['biodegradable', 'non_biodegradable']\n",
    "num_classes = len(waste_categories)\n",
    "\n",
    "# Image dimensions\n",
    "img_width, img_height = 128, 128\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Build CNN Model\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile the model\n",
    "model = build_cnn_model(input_shape, num_classes)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Data Generators with Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dataset_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dataset_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Debug: Check Detected Classes\n",
    "print(\"Class labels detected by train generator:\", train_generator.class_indices)\n",
    "print(\"Class labels detected by test generator:\", test_generator.class_indices)\n",
    "\n",
    "# Train the Model\n",
    "model.fit(train_generator, epochs=10, validation_data=test_generator)\n",
    "\n",
    "# Save the Model\n",
    "model.save('waste_classification_model.keras')\n",
    "\n",
    "# Load the Model for Testing\n",
    "model = tf.keras.models.load_model('waste_classification_model.keras')\n",
    "\n",
    "# Function to Preprocess Images for Classification\n",
    "def validate_and_preprocess_image(image_path_or_url):\n",
    "    try:\n",
    "        if image_path_or_url.startswith(('http://', 'https://')):\n",
    "            response = requests.get(image_path_or_url)\n",
    "            response.raise_for_status()\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "        else:\n",
    "            img = Image.open(image_path_or_url)\n",
    "\n",
    "        img = img.convert('RGB')\n",
    "        img = np.array(img)\n",
    "\n",
    "        # Resize and normalize the image\n",
    "        img = cv2.resize(img, (img_width, img_height), interpolation=cv2.INTER_LINEAR)\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Invalid image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to Classify Waste Type\n",
    "def classify_waste(image_path_or_url):\n",
    "    img = validate_and_preprocess_image(image_path_or_url)\n",
    "    if img is None:\n",
    "        return {\"status\": \"error\", \"message\": \"Invalid image. Please upload a valid image.\"}\n",
    "\n",
    "    predictions = model.predict(img)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    waste_type = waste_categories[predicted_class]\n",
    "    confidence = float(predictions[0][predicted_class])\n",
    "\n",
    "    return {\"status\": \"success\", \"waste_type\": waste_type, \"confidence\": confidence}\n",
    "\n",
    "# Example Usage\n",
    "image_path = r\"biodnonbiodddatset\\val\\biodegradable\\paper_waste\\paper567.jpg\"\n",
    "result = classify_waste(image_path)\n",
    "\n",
    "# Display Output\n",
    "if result[\"status\"] == \"success\":\n",
    "    print(f\"Detected Waste Type: {result['waste_type']} (Confidence: {result['confidence']:.2%})\")\n",
    "else:\n",
    "    print(\"Error:\", result[\"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020C3E0CF060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "Detected Waste Type: non_biodegradable (Confidence: 83.98%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Image dimensions\n",
    "img_width, img_height = 128, 128\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Waste categories (must match folder names used during training)\n",
    "waste_categories = ['biodegradable', 'non_biodegradable']\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('waste_classification_model.keras')\n",
    "\n",
    "# Function to preprocess the image\n",
    "def validate_and_preprocess_image(image_path_or_url):\n",
    "    try:\n",
    "        if image_path_or_url.startswith(('http://', 'https://')):\n",
    "            response = requests.get(image_path_or_url)\n",
    "            response.raise_for_status()\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "        else:\n",
    "            if not os.path.exists(image_path_or_url):\n",
    "                print(f\"Error: File not found - {image_path_or_url}\")\n",
    "                return None\n",
    "            img = Image.open(image_path_or_url)\n",
    "\n",
    "        img = img.convert('RGB')\n",
    "        img = np.array(img)\n",
    "\n",
    "        # Resize and normalize\n",
    "        img = cv2.resize(img, (img_width, img_height), interpolation=cv2.INTER_LINEAR)\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Invalid image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to classify waste\n",
    "def classify_waste(image_path_or_url):\n",
    "    img = validate_and_preprocess_image(image_path_or_url)\n",
    "    if img is None:\n",
    "        return {\"status\": \"error\", \"message\": \"Invalid or missing image.\"}\n",
    "\n",
    "    # Make predictions on the new image\n",
    "    predictions = model.predict(img)\n",
    "    predicted_class = np.argmax(predictions[0])  # Get index of class with highest probability\n",
    "    waste_type = waste_categories[predicted_class]\n",
    "    confidence = float(predictions[0][predicted_class])\n",
    "\n",
    "    return {\"status\": \"success\", \"waste_type\": waste_type, \"confidence\": confidence}\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"biodnonbiodddatset\\train\\non_biodegradable\\ewaste\\00000255.jpg\"  # Replace with the path to your image\n",
    "\n",
    "if os.path.exists(image_path):\n",
    "    result = classify_waste(image_path)\n",
    "    print(f\"Detected Waste Type: {result['waste_type']} (Confidence: {result['confidence']:.2%})\")\n",
    "else:\n",
    "    print(\"Error: Image file does not exist. Please check the path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
